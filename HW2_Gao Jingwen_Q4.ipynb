{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic4ac2c4jjXo"
      },
      "source": [
        "# Assignment 2 - Question 4: Convolutional Neural Network - Colab Version\n",
        "**Course Name:** Machine Learning (DDA3020)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4D2u39KjjXp"
      },
      "source": [
        "<font color=Red>*Please enter your personal information (Double-click this block first)*</font>\n",
        "\n",
        "**Name:**\n",
        "\n",
        "**Student ID:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGzEVVQ0jjXp"
      },
      "source": [
        "**It's highly recommended to finish Question 3 first.**\n",
        "\n",
        "### Overview\n",
        "\n",
        "In this question, you will implement two CNN models and train them on the same dataset as Question 3 (Fasion-MNIST). We will discover how well-suited CNNs are for intensive data tasks such as image processing, compared to traditional machine learning algorithms (like those tree tree-based models in Question 3). Similarly, your task is to **run all codes in this script and complete the parts marked with** <font color=Red>\\[TASK\\]</font>.\n",
        "\n",
        "### Introduction of TensorFlow\n",
        "\n",
        "TensorFlow is a powerful open-source package for machine learning and deep learning, enabling efficient implementation of complex models like neural networks with ease. By using this version on Colab, you don't need to install any additional packages.\n",
        "\n",
        "To check whether the package is successfully installed, you can try to run the following import block."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "3Tdh7W_xjjXp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gzip\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2atsHGLujjXq"
      },
      "source": [
        "Don't need to carefully read this block since it's just loading the dataset. Just run it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QwU9XGTujjXq"
      },
      "outputs": [],
      "source": [
        "def load_mnist(path, kind, subset=None):\n",
        "    labels_path = os.path.join(path, '%s-labels-idx1-ubyte.gz'%kind)\n",
        "    images_path = os.path.join(path, '%s-images-idx3-ubyte.gz'%kind)\n",
        "\n",
        "    with gzip.open(labels_path, 'rb') as lbpath:\n",
        "        labels = np.frombuffer(lbpath.read(), dtype=np.uint8, offset=8)\n",
        "    with gzip.open(images_path, 'rb') as imgpath:\n",
        "        images = np.frombuffer(imgpath.read(), dtype=np.uint8, offset=16).reshape(len(labels), 784)\n",
        "\n",
        "    if subset is not None:\n",
        "        selected_images, selected_labels = [], []\n",
        "        for label in range(10):\n",
        "            indices = np.where(labels == label)[0]\n",
        "            selected_indices = np.random.choice(indices, subset, replace=False)\n",
        "            selected_images.append(images[selected_indices])\n",
        "            selected_labels.append(labels[selected_indices])\n",
        "        images = np.concatenate(selected_images, axis=0)\n",
        "        labels = np.concatenate(selected_labels, axis=0)\n",
        "\n",
        "        paired = list(zip(images, labels))\n",
        "        random.shuffle(paired)\n",
        "        images, labels = zip(*paired)\n",
        "\n",
        "    return np.array(images), np.array(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLWb3VijjjXq"
      },
      "source": [
        "In this question, we will use all data of Fashion-MNIST and do a little bit data preprocessing. Here we add some addtional code to help download the data and put it on the right position, so that we don't need to manually upload it every time."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir data\n",
        "! wget -q -P ./data/ http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
        "! wget -q -P ./data/ http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
        "! wget -q -P ./data/ http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
        "! wget -q -P ./data/ http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz"
      ],
      "metadata": {
        "id": "Ye-OBQpkjyek",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887d6963-c7b3-44be-e868-71d5a4f1eb31"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Wz4DCtrkjjXq"
      },
      "outputs": [],
      "source": [
        "X_train, y_train = load_mnist('./data/', kind='train')\n",
        "X_test, y_test = load_mnist('./data/', kind='t10k')\n",
        "\n",
        "X_train = X_train.reshape((X_train.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], 28, 28, 1)).astype('float32') / 255\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATIfJRfBjjXq"
      },
      "source": [
        "If you are familiar with TensorFlow or PyTorch, you can straightly start Task 1. Otherwise, it's highly recommended to start from https://www.tensorflow.org/tutorials/images/cnn to gain some basic capacity on building neural network by TensorFlow.\n",
        "\n",
        "### Task 1\n",
        "\n",
        "At the beginning, we need to build a very simple CNN model with the structure of\n",
        "1. A 2D convolutional layer with 16 filters with each size 3*3 (RELU activation function)\n",
        "2. A 2D maxpooling layer with 2*2 pooling window\n",
        "3. A flatten layer to convert 2D feature into 1D vector\n",
        "4. A fully connected layer using Softmax activation\n",
        "\n",
        "Remember that we are doing a image classification task, so we shall use categorical cross entropy function as the loss funtion. <font color=Red>\\[TASK\\]</font> (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "n1g6zsqFjjXq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf20b77-007c-412b-c55d-324bd53f2af9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.7663 - loss: 0.6756 - val_accuracy: 0.8643 - val_loss: 0.3989\n",
            "Epoch 2/2\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8701 - loss: 0.3770 - val_accuracy: 0.8793 - val_loss: 0.3435\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8827 - loss: 0.3525\n"
          ]
        }
      ],
      "source": [
        "##########################\n",
        "## Write your code here ##\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "##########################\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=2, batch_size=32, validation_split=0.1)  # Train the model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)                        #  Test the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WM6rWiFjjXq"
      },
      "source": [
        "### Task 2\n",
        "\n",
        "Then we will take a challenge to implement a more complex CNN model to have a better classification performance. Here is a structure for your reference, or you can also design your own CNN model. The only requirement is to have a better performance than the simple CNN in Task 1 (a larger accuracy score on test set).\n",
        "\n",
        "The reference structure is devided into three parts:\n",
        "1. Primary Feature Extraction Part\n",
        "    1. A 2D convolutional layer with 32 filters with each size 3*3 (RELU activation function)\n",
        "    2. A normalization layer\n",
        "    3. A 2D maxpooling layer with 2*2 pooling window\n",
        "    4. A dropout layer (randomly drops 25% of units) (designed for preventing overfitting)\n",
        "2. Advanced Feature Extraction Part\n",
        "\n",
        "    This part is mostly similar to the previous section. The only difference is to use more filters (like 64) in convolutional layer to gain high-level features\n",
        "3. Classification Part\n",
        "    1. A flatten layer to convert 2D feature into 1D vector\n",
        "    2. A fully connected layer with 512 units using RELU to summerize high-dimensinal features\n",
        "    3. Another connected layer for Softmax classification\n",
        "\n",
        "Remember that we are doing a image classification task, so we shall use categorical cross entropy function as the loss funtion. <font color=Red>\\[TASK\\]</font> (10 points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "m8-Y_e68jjXr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fa26508-c21a-4c95-c981-9725f4034a99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.7924 - loss: 0.6304 - val_accuracy: 0.8780 - val_loss: 0.3357\n",
            "Epoch 2/2\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.3122 - val_accuracy: 0.8868 - val_loss: 0.3151\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8839 - loss: 0.3459\n"
          ]
        }
      ],
      "source": [
        "##########################\n",
        "## Write your code here ##\n",
        "model = models.Sequential([\n",
        "    layers.Conv2D(32,(3,3),activation='relu',input_shape=(28,28,1)),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Conv2D(64,(3,3),activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.MaxPooling2D((2,2)),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512,activation='relu'),\n",
        "    layers.Dense(10,activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "##########################\n",
        "\n",
        "\n",
        "model.fit(X_train, y_train, epochs=2, batch_size=32, validation_split=0.1)\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}